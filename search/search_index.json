{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to Beedata Analytics technical notes For full documentation visit mkdocs.org . How to add a note Create a new .md file on docs directory Commands mkdocs build - Build the documentation site. mkdocs gh-deploy - Deploy documentation to https://beedata-analytics.github.io/technical-notes/ . Project layout mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Welcome to Beedata Analytics technical notes"},{"location":"#welcome-to-beedata-analytics-technical-notes","text":"For full documentation visit mkdocs.org .","title":"Welcome to Beedata Analytics technical notes"},{"location":"#how-to-add-a-note","text":"Create a new .md file on docs directory","title":"How to add a note"},{"location":"#commands","text":"mkdocs build - Build the documentation site. mkdocs gh-deploy - Deploy documentation to https://beedata-analytics.github.io/technical-notes/ .","title":"Commands"},{"location":"#project-layout","text":"mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Project layout"},{"location":"ambari-cannot-connect-to-a-data-node/","text":"Ambari cannot connect to a data node Probably OpenVPN service is down and Zookeeper cannot ping the node. To restart the service: sudo ssh bee1-vpn sudo systemctl restart openvpn@bee1.service","title":"Ambari cannot connect to a data node"},{"location":"ambari-cannot-connect-to-a-data-node/#ambari-cannot-connect-to-a-data-node","text":"Probably OpenVPN service is down and Zookeeper cannot ping the node. To restart the service: sudo ssh bee1-vpn sudo systemctl restart openvpn@bee1.service","title":"Ambari cannot connect to a data node"},{"location":"check-region-consistency-and-table-integrity-problems-on-hbase/","text":"Check region consistency and table integrity problems on HBase HBaseFsck (hbck) is a tool for checking for region consistency and table integrity problems and repairing a corrupted HBase. It works in two basic modes\u2009\u2014\u2009a read-only inconsistency identifying mode and a multi-phase read-write repair mode. To check to see if your HBase cluster has corruptions, run hbck against your HBase cluster: $ hbase hbck At the end of the commands output it prints OK or tells you the number of INCONSISTENCIES present. You may also want to run hbck a few times because some inconsistencies can be transient (e.g. cluster is starting up or a region is splitting). Operationally you may want to run hbck regularly and setup alert if it repeatedly reports inconsistencies . A run of hbck will report a list of inconsistencies along with a brief description of the regions and tables affected. The using the -details option will report more details including a representative listing of all the splits present in all the tables. $ hbase hbck -details If you just want to know if some tables are corrupted, you can limit hbck to identify inconsistencies in only specific tables. For example the following command would only attempt to check table TableFoo and TableBar. The benefit is that hbck will run in less time. $ hbase hbck powerConsumption_6161024077_devices To repair a table run: $ sudo -u hbase hbase hbck -repair powerConsumption_6161024077_devices","title":"Check region consistency and table integrity problems on HBase"},{"location":"check-region-consistency-and-table-integrity-problems-on-hbase/#check-region-consistency-and-table-integrity-problems-on-hbase","text":"HBaseFsck (hbck) is a tool for checking for region consistency and table integrity problems and repairing a corrupted HBase. It works in two basic modes\u2009\u2014\u2009a read-only inconsistency identifying mode and a multi-phase read-write repair mode. To check to see if your HBase cluster has corruptions, run hbck against your HBase cluster: $ hbase hbck At the end of the commands output it prints OK or tells you the number of INCONSISTENCIES present. You may also want to run hbck a few times because some inconsistencies can be transient (e.g. cluster is starting up or a region is splitting). Operationally you may want to run hbck regularly and setup alert if it repeatedly reports inconsistencies . A run of hbck will report a list of inconsistencies along with a brief description of the regions and tables affected. The using the -details option will report more details including a representative listing of all the splits present in all the tables. $ hbase hbck -details If you just want to know if some tables are corrupted, you can limit hbck to identify inconsistencies in only specific tables. For example the following command would only attempt to check table TableFoo and TableBar. The benefit is that hbck will run in less time. $ hbase hbck powerConsumption_6161024077_devices To repair a table run: $ sudo -u hbase hbase hbck -repair powerConsumption_6161024077_devices","title":"Check region consistency and table integrity problems on HBase"},{"location":"decommissioning-data-nodes/","text":"Decommissioning datanodes in Hadoop cluster Decommissioning process of the data node ensures that data is transferred to other nodes so that the existing replication factor is not disturbed. Update dfs.exclude file $ vi /etc/hadoop/conf/dfs.exclude bee2-vpn Run refreshNodes command $ sudo -u hdfs hdfs dfs -refreshNodes","title":"Decommissioning datanodes in Hadoop cluster"},{"location":"decommissioning-data-nodes/#decommissioning-datanodes-in-hadoop-cluster","text":"Decommissioning process of the data node ensures that data is transferred to other nodes so that the existing replication factor is not disturbed.","title":"Decommissioning datanodes in Hadoop cluster"},{"location":"decommissioning-data-nodes/#update-dfsexclude-file","text":"$ vi /etc/hadoop/conf/dfs.exclude bee2-vpn","title":"Update dfs.exclude file"},{"location":"decommissioning-data-nodes/#run-refreshnodes-command","text":"$ sudo -u hdfs hdfs dfs -refreshNodes","title":"Run refreshNodes command"},{"location":"extract-7z-file-in-linux/","text":"Extract 7z file in Linux Install p7zip sudo apt update && sudo apt install --assume-yes p7zip-full Extract using 7z command 7z x ~/archive.7z","title":"Extract 7z file in Linux"},{"location":"extract-7z-file-in-linux/#extract-7z-file-in-linux","text":"Install p7zip sudo apt update && sudo apt install --assume-yes p7zip-full Extract using 7z command 7z x ~/archive.7z","title":"Extract 7z file in Linux"},{"location":"fast-string-search-in-a-very-large-file/","text":"Fast string search in a very large file To search a single pattern: grep -F pattern large_file To search a multiple patterns: grep -F -f pattern_file large_file","title":"Fast string search in a very large file"},{"location":"fast-string-search-in-a-very-large-file/#fast-string-search-in-a-very-large-file","text":"To search a single pattern: grep -F pattern large_file To search a multiple patterns: grep -F -f pattern_file large_file","title":"Fast string search in a very large file"},{"location":"find-a-file-by-name%20from%20a%20directory/","text":"Find a file by name from a directory find . -iname '*pattern*'","title":"Find a file by name from a directory"},{"location":"find-a-file-by-name%20from%20a%20directory/#find-a-file-by-name-from-a-directory","text":"find . -iname '*pattern*'","title":"Find a file by name from a directory"},{"location":"find-all-files-containing-specific-text-on-linux/","text":"Find all files containing specific text on Linux $ grep -rnw '/path/to/somewhere/' -e 'pattern' -r or -R is recursive, -n is line number, and -w stands for match the whole word. -l (lower-case L) can be added to just give the file name of matching files. -e is the pattern used during the search Along with these, --exclude, --include, --exclude-dir flags could be used for efficient searching.","title":"Find all files containing specific text on Linux"},{"location":"find-all-files-containing-specific-text-on-linux/#find-all-files-containing-specific-text-on-linux","text":"$ grep -rnw '/path/to/somewhere/' -e 'pattern' -r or -R is recursive, -n is line number, and -w stands for match the whole word. -l (lower-case L) can be added to just give the file name of matching files. -e is the pattern used during the search Along with these, --exclude, --include, --exclude-dir flags could be used for efficient searching.","title":"Find all files containing specific text on Linux"},{"location":"hadoop-safe-mode/","text":"How to leave Hadoop safe mode The Hadoop cluster enters safe mode during the name node startup till the basic indicators are met and later in case of emergency, which means that the cluster enters read-only mode. The client will immediately notice that the name node is in safe mode. $ hdfs dfs -copyFromLocal -f /var/log/syslog /logs/backup/ copyFromLocal: Cannot create file/logs/backup/syslog._COPYING_. Name node is in safe mode. Determine current safe mode status. $ hdfs dfsadmin -safemode get Safe mode is ON Disable safe mode . $ hdfs dfsadmin -safemode leave Safe mode is OFF","title":"How to leave Hadoop safe mode"},{"location":"hadoop-safe-mode/#how-to-leave-hadoop-safe-mode","text":"The Hadoop cluster enters safe mode during the name node startup till the basic indicators are met and later in case of emergency, which means that the cluster enters read-only mode. The client will immediately notice that the name node is in safe mode. $ hdfs dfs -copyFromLocal -f /var/log/syslog /logs/backup/ copyFromLocal: Cannot create file/logs/backup/syslog._COPYING_. Name node is in safe mode. Determine current safe mode status. $ hdfs dfsadmin -safemode get Safe mode is ON Disable safe mode . $ hdfs dfsadmin -safemode leave Safe mode is OFF","title":"How to leave Hadoop safe mode"},{"location":"output-a-brief-report-on-the-overall-hdfs-filesystem/","text":"Output a brief report on the overall HDFS filesystem hdfs dfsadmin -report outputs a brief report on the overall HDFS filesystem. It\u2019s a useful command to quickly view how much disk is available, how many DataNodes are running, corrupted blocks etc. sudo -u hdfs hdfs dfsadmin -report","title":"Output a brief report on the overall HDFS filesystem"},{"location":"output-a-brief-report-on-the-overall-hdfs-filesystem/#output-a-brief-report-on-the-overall-hdfs-filesystem","text":"hdfs dfsadmin -report outputs a brief report on the overall HDFS filesystem. It\u2019s a useful command to quickly view how much disk is available, how many DataNodes are running, corrupted blocks etc. sudo -u hdfs hdfs dfsadmin -report","title":"Output a brief report on the overall HDFS filesystem"}]}